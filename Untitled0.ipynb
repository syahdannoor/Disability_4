{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjK2AuaaSDNH",
        "outputId": "751c893f-25a9-45e1-f203-eed9608a63dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "import pickle\n",
        "import numpy as np\n",
        "# Get a ResNet50 model\n",
        "def resnet50_model(classes=1000, *args, **kwargs):\n",
        "    # Load a model if we have saved one\n",
        "    if(os.path.isfile('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5') == True):\n",
        "        return keras.models.load_model('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "    # Create an input layer \n",
        "    input = keras.layers.Input(shape=(None, None, 3))\n",
        "    # Create output layers\n",
        "    output = keras.layers.ZeroPadding2D(padding=3, name='padding_conv1')(input)\n",
        "    output = keras.layers.Conv2D(64, (7, 7), strides=(2, 2), use_bias=False, name='conv1')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, epsilon=1e-5, name='bn_conv1')(output)\n",
        "    output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
        "    output = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='pool1')(output)\n",
        "    output = conv_block(output, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
        "    output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
        "    output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    output = keras.layers.GlobalAveragePooling2D(name='pool5')(output)\n",
        "    output = keras.layers.Dense(classes, activation='softmax', name='fc1000')(output)\n",
        "    # Create a model from input layer and output layers\n",
        "    model = keras.models.Model(inputs=input, outputs=output, *args, **kwargs)\n",
        "    # Print model\n",
        "    print()\n",
        "    # print(model.summary(), '\\n')\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    # Return a model\n",
        "    return model\n",
        "# Create an identity block\n",
        "def identity_block(input, kernel_size, filters, stage, block):\n",
        "    \n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
        "    output = keras.layers.add([output, input])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output\n",
        "# Create a convolution block\n",
        "def conv_block(input, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create block layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
        "    shortcut = keras.layers.Conv2D(filters3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
        "    shortcut = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '1')(shortcut)\n",
        "    output = keras.layers.add([output, shortcut])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output"
      ],
      "metadata": {
        "id": "7Ea3m5UATB83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    # Variables, 25 epochs so far\n",
        "    epochs = 100\n",
        "    batch_size = 32\n",
        "    train_samples = 26 * 5000 # 10 categories with 5000 images in each category\n",
        "    validation_samples = 16 * 1000 # 10 categories with 1000 images in each category\n",
        "    img_width, img_height = 32, 32\n",
        "    # Get the model (10 categories)\n",
        "    model = resnet50_model(26)\n",
        "    # Create a data generator for training\n",
        "    train_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255, \n",
        "        shear_range=0.2, \n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "    # Create a data generator for validation\n",
        "    validation_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "    # Create a train generator\n",
        "    train_generator = train_data_generator.flow_from_directory( \n",
        "        '/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/', \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "    # Create a test generator\n",
        "    validation_generator = validation_data_generator.flow_from_directory( \n",
        "        '/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/', \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "    # Start training, fit the model\n",
        "    hist = model.fit_generator( \n",
        "        train_generator, \n",
        "        # steps_per_epoch=train_samples // batch_size, \n",
        "        validation_data=validation_generator, \n",
        "        validation_steps=validation_samples // batch_size,\n",
        "        epochs=epochs)\n",
        "    # Save model to disk\n",
        "    model.save('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "    print('Saved model to disk!')\n",
        "    # Get labels\n",
        "    labels = train_generator.class_indices\n",
        "    # Invert labels\n",
        "    classes = {}\n",
        "    for key, value in labels.items():\n",
        "        classes[value] = key.capitalize()\n",
        "    # Save classes to file\n",
        "    with open('/content/drive/MyDrive/colab_notebook/digitalent/model/classes.pkl', 'wb') as file:\n",
        "        pickle.dump(classes, file)\n",
        "    print('Saved classes to disk!')\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "UVQlylhgTGY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9fI_igK_TQLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.shape\n",
        "# input.reshape(1, 32, 32, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAHMIWhVoVsc",
        "outputId": "9ca2ad0b-74ba-4109-cfc6-b6a6bafe083e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 3000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "model = keras.models.load_model('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "with open('/content/drive/MyDrive/colab_notebook/digitalent/model/classes.pkl', 'rb') as file:\n",
        "        classes = pickle.load(file)\n",
        "image = cv2.imread('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/A/wall white (3).jpg')\n",
        "input = np.array(image)\n",
        "input = np.array(image).reshape((1, 3000, 3000, 3)).astype('float32')/255\n",
        "predictions = model.predict(input).ravel()\n",
        "image = cv2.resize(image,(256,256))\n",
        "#         # Print predictions\n",
        "# print(predictions)\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "l31cE43TzYUS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# img = cv2.imread('your_image.jpg')\n",
        "res = cv2.resize(image, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "res.shape\n",
        "# input = np.array(image)\n",
        "input = np.array(res).reshape((1, 32, 32, 3)).astype('float32')/255"
      ],
      "metadata": {
        "id": "hFEKAlVL7un4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "# Evaluate the model\n",
        "def evaluate():\n",
        "    # Load the model\n",
        "    model = keras.models.load_model('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "    # Load classes\n",
        "    classes = {}\n",
        "    with open('/content/drive/MyDrive/colab_notebook/digitalent/model/classes.pkl', 'rb') as file:\n",
        "        classes = pickle.load(file)\n",
        "    # Get a list of categories\n",
        "    categories = os.listdir('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/')\n",
        "    # Get a category a random\n",
        "    category = random.choice(categories)\n",
        "    # Print the category\n",
        "    print(category)\n",
        "    # Get images in a categorydd\n",
        "    images =  os.listdir('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/' + category)\n",
        "    # Randomize images to get different images each time\n",
        "    random.shuffle(images)\n",
        "    # Loop images\n",
        "    blocks = []\n",
        "    for i, name in enumerate(images):\n",
        "        # Limit the evaluation\n",
        "        if i > 6:\n",
        "            break;\n",
        "        # Print the name\n",
        "        print(name)\n",
        "        # Get the image\n",
        "        image = cv2.imread('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/' + category + '/' + name)\n",
        "        # Get input reshaped and rescaled\n",
        "        res = cv2.resize(image, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "        input = np.array(res).reshape((1, 32, 32, 3)).astype('float32')/255\n",
        "        # Get predictions\n",
        "        predictions = model.predict(input).ravel()\n",
        "        # Print predictions\n",
        "        print(predictions)\n",
        "        # Get the class with the highest probability\n",
        "        prediction = np.argmax(predictions)\n",
        "        # Check if the prediction is correct\n",
        "        correct = True if classes[prediction].lower() == category else False\n",
        "        # Draw the image and show the best prediction\n",
        "        image = cv2.resize(image,(256,256))\n",
        "        cv2.putText(image, '{0}: {1} %'.format(classes[prediction], str(round(predictions[prediction] * 100, 2))), (12, 22), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 0), 2)\n",
        "        cv2.putText(image, '{0}: {1} %'.format(classes[prediction], str(round(predictions[prediction] * 100, 2))), (10, 20), cv2.FONT_HERSHEY_DUPLEX, 0.7, (65,105,225), 2)\n",
        "        cv2.putText(image, '{0}'.format('CORRECT!' if correct else 'WRONG!'), (12, 50), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 0), 2)\n",
        "        cv2.putText(image, '{0}'.format('CORRECT!' if correct else 'WRONG!'), (10, 48), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 0) if correct else (0, 0, 255), 2)\n",
        "        \n",
        "        # Append the image\n",
        "        blocks.append(image)\n",
        "        \n",
        "    # Display images and predictions\n",
        "    row1 = np.concatenate(blocks[0:3], axis=1)\n",
        "    row2 = np.concatenate(blocks[3:6], axis=1)\n",
        "    # cv2.imshow('Predictions', np.concatenate((row1, row2), axis=0))\n",
        "    cv2.imwrite('predictions.jpg', np.concatenate((row1, row2), axis=0)) \n",
        "    cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "Gz-0gxCD6Gkj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XSsN9HbkyEGC",
        "outputId": "d7bde38a-067e-414e-a0cb-b39c2054bc90"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U\n",
            "wall white (2).jpg\n",
            "[2.2405947e-08 3.7138659e-10 1.2348137e-06 9.2546920e-10 3.4516641e-09\n",
            " 3.1691336e-10 5.9333653e-12 5.8854180e-08 4.4859471e-06 4.3350749e-07\n",
            " 7.4131044e-09 3.4365996e-06 2.0959584e-08 1.9439391e-08 4.7350866e-08\n",
            " 5.2450583e-10 2.3440197e-08 2.2738803e-05 7.9613002e-08 1.5881700e-06\n",
            " 9.9909055e-01 8.7442953e-04 3.7676966e-07 1.1649262e-09 1.3802293e-07\n",
            " 3.5177391e-07]\n",
            "body dot (2).jpg\n",
            "[1.0787662e-06 8.0139088e-08 1.1971333e-06 5.4715713e-08 2.8912236e-08\n",
            " 2.4066567e-08 3.3144262e-11 4.6642117e-06 1.5661611e-06 6.6705206e-07\n",
            " 8.3248173e-09 4.2407888e-07 4.3305988e-08 1.2706187e-06 1.1189374e-07\n",
            " 1.8858099e-08 1.2788323e-07 1.8543409e-07 6.6689081e-06 2.0490687e-03\n",
            " 9.9713755e-01 3.4807253e-04 4.1038747e-04 2.1785878e-08 1.9785466e-06\n",
            " 3.4606008e-05]\n",
            "body dot (4).jpg\n",
            "[5.8329785e-09 3.1480624e-08 1.5301073e-07 2.3553445e-08 1.7508778e-08\n",
            " 3.7810901e-09 9.5110309e-12 2.3475006e-06 4.8302434e-07 5.2045923e-08\n",
            " 3.3048977e-08 5.6745137e-07 6.1214067e-08 6.6079323e-08 2.7019323e-07\n",
            " 8.9339993e-09 3.9279207e-08 1.1735891e-07 5.9409268e-07 6.4862797e-05\n",
            " 9.9949825e-01 4.2876863e-04 2.4012477e-06 1.0020897e-09 4.4761447e-07\n",
            " 3.3420392e-07]\n",
            "body white (1).jpg\n",
            "[8.0332586e-07 5.0836000e-08 7.9891415e-06 1.8469013e-08 1.4794429e-08\n",
            " 6.5373609e-09 4.8696061e-11 7.2376665e-06 1.1580685e-06 7.2054104e-07\n",
            " 3.7908952e-09 2.0075249e-04 9.1568779e-08 5.5344043e-07 2.6595623e-07\n",
            " 2.7654874e-08 8.1606322e-06 5.5500573e-06 4.8484348e-05 4.6969367e-06\n",
            " 1.7033297e-01 8.2924056e-01 1.3581067e-04 1.2388612e-08 2.8598154e-07\n",
            " 3.7893935e-06]\n",
            "body white (4).jpg\n",
            "[1.0268239e-04 1.4204420e-05 1.7894503e-04 1.7490542e-05 2.0846983e-06\n",
            " 4.5696714e-07 5.9659513e-09 2.3242921e-04 1.0099683e-05 1.6310767e-05\n",
            " 5.0640392e-07 2.2601182e-05 2.4715664e-06 5.9251954e-05 6.7153618e-05\n",
            " 5.3425665e-06 1.2793113e-04 1.5240223e-05 5.4773421e-04 5.9682488e-02\n",
            " 9.3438214e-01 1.3983735e-03 2.3516510e-03 2.8726670e-06 1.2169839e-05\n",
            " 7.4737304e-04]\n",
            "wall white (1).jpg\n",
            "[1.2847559e-08 1.2491841e-08 2.6267571e-08 6.7066326e-09 1.5440651e-07\n",
            " 2.2394673e-09 4.1105279e-12 1.6228668e-08 9.0067306e-07 1.7389712e-06\n",
            " 7.2197747e-07 6.1197154e-09 3.0068439e-09 2.7985374e-08 6.1470345e-08\n",
            " 4.6194895e-10 2.5631838e-08 1.4720525e-05 6.2945603e-08 5.2641572e-05\n",
            " 9.9986899e-01 2.8785582e-06 5.5692708e-05 6.6906618e-09 1.2367242e-07\n",
            " 1.0491065e-06]\n",
            "body white (3).jpg\n",
            "[8.8066292e-05 8.6786156e-07 1.1666337e-05 3.0212666e-06 4.5565653e-07\n",
            " 1.9370223e-07 1.2056079e-09 8.8827961e-05 1.4462111e-05 6.1552339e-05\n",
            " 4.6023519e-07 9.9761924e-03 3.0876918e-06 1.3567878e-04 2.7359840e-06\n",
            " 1.9350873e-07 3.8528923e-04 7.5917596e-05 6.9182757e-03 1.9885167e-04\n",
            " 8.0365109e-01 1.5746613e-01 2.0796632e-02 3.2834171e-07 2.8457129e-05\n",
            " 9.1600305e-05]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3f393ad04e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-0ba8b5b3ca82>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mrow1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mrow2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predictions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ]
    }
  ]
}