{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjK2AuaaSDNH",
        "outputId": "b17f426f-d67b-4592-e1f0-4c67126c1dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "import pickle\n",
        "import numpy as np\n",
        "# Get a ResNet50 model\n",
        "def resnet50_model(classes=1000, *args, **kwargs):\n",
        "    # Load a model if we have saved one\n",
        "    if(os.path.isfile('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5') == True):\n",
        "        return keras.models.load_model('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "    # Create an input layer \n",
        "    input = keras.layers.Input(shape=(None, None, 3))\n",
        "    # Create output layers\n",
        "    output = keras.layers.ZeroPadding2D(padding=3, name='padding_conv1')(input)\n",
        "    output = keras.layers.Conv2D(64, (7, 7), strides=(2, 2), use_bias=False, name='conv1')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, epsilon=1e-5, name='bn_conv1')(output)\n",
        "    output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
        "    output = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='pool1')(output)\n",
        "    output = conv_block(output, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
        "    output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
        "    output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    output = keras.layers.GlobalAveragePooling2D(name='pool5')(output)\n",
        "    output = keras.layers.Dense(classes, activation='softmax', name='fc1000')(output)\n",
        "    # Create a model from input layer and output layers\n",
        "    model = keras.models.Model(inputs=input, outputs=output, *args, **kwargs)\n",
        "    # Print model\n",
        "    print()\n",
        "    # print(model.summary(), '\\n')\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    # Return a model\n",
        "    return model\n",
        "# Create an identity block\n",
        "def identity_block(input, kernel_size, filters, stage, block):\n",
        "    \n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
        "    output = keras.layers.add([output, input])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output\n",
        "# Create a convolution block\n",
        "def conv_block(input, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create block layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
        "    shortcut = keras.layers.Conv2D(filters3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
        "    shortcut = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '1')(shortcut)\n",
        "    output = keras.layers.add([output, shortcut])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output"
      ],
      "metadata": {
        "id": "7Ea3m5UATB83"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    # Variables, 25 epochs so far\n",
        "    epochs = 100\n",
        "    batch_size = 32\n",
        "    train_samples = 26 * 5000 # 10 categories with 5000 images in each category\n",
        "    validation_samples = 16 * 1000 # 10 categories with 1000 images in each category\n",
        "    img_width, img_height = 32, 32\n",
        "    # Get the model (10 categories)\n",
        "    model = resnet50_model(26)\n",
        "    # Create a data generator for training\n",
        "    train_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255, \n",
        "        shear_range=0.2, \n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "    # Create a data generator for validation\n",
        "    validation_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "    # Create a train generator\n",
        "    train_generator = train_data_generator.flow_from_directory( \n",
        "        '/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/', \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "    # Create a test generator\n",
        "    validation_generator = validation_data_generator.flow_from_directory( \n",
        "        '/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/', \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "    # Start training, fit the model\n",
        "    hist = model.fit_generator( \n",
        "        train_generator, \n",
        "        # steps_per_epoch=train_samples // batch_size, \n",
        "        validation_data=validation_generator, \n",
        "        validation_steps=validation_samples // batch_size,\n",
        "        epochs=epochs)\n",
        "    # Save model to disk\n",
        "    model.save('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "    print('Saved model to disk!')\n",
        "    # Get labels\n",
        "    labels = train_generator.class_indices\n",
        "    # Invert labels\n",
        "    classes = {}\n",
        "    for key, value in labels.items():\n",
        "        classes[value] = key.capitalize()\n",
        "    # Save classes to file\n",
        "    with open('/content/drive/MyDrive/colab_notebook/digitalent/model/classes.pkl', 'wb') as file:\n",
        "        pickle.dump(classes, file)\n",
        "    print('Saved classes to disk!')\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "UVQlylhgTGY_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9fI_igK_TQLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input.shape\n",
        "# input.reshape(1, 32, 32, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAHMIWhVoVsc",
        "outputId": "2f61a0e8-f283-465a-ba1f-e47626734341"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 3000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "model = keras.models.load_model('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "image = cv2.imread('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/F/wall white (3).jpg')\n",
        "input = np.array(image)\n",
        "input = np.array(image).reshape((1, 1078, 1077, 3)).astype('float32')/255\n",
        "predictions = model.predict(input).ravel()\n",
        "#         # Print predictions\n",
        "# print(predictions)\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "l31cE43TzYUS",
        "outputId": "35fdcd50-3d51-45c4-a707-d11a53c53437"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ea5170bce4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/F/wall white (3).jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1078\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1077\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         # Print predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 27000000 into shape (1,1078,1077,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prediction = np.argmax(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn0WOUtfrNa8",
        "outputId": "dcf1a582-fd78-4432-d102-e86cde3fdbc3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.46128532e-05 2.56389012e-05 2.33917356e-12 7.45359762e-03\n",
            " 1.25030547e-05 8.42512782e-06 1.66307243e-15 1.34752609e-05\n",
            " 1.07581615e-08 5.30324110e-14 2.36428464e-11 1.91906845e-04\n",
            " 1.34898679e-16 1.84460222e-13 3.72873130e-12 1.35459807e-02\n",
            " 4.40680104e-10 5.19755986e-06 1.53175210e-06 1.80834306e-11\n",
            " 1.45301148e-22 1.29624532e-11 9.78095174e-01 7.68029349e-06\n",
            " 1.92394347e-11 5.54304570e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "# Evaluate the model\n",
        "def evaluate():\n",
        "    # Load the model\n",
        "    model = keras.models.load_model('/content/drive/MyDrive/colab_notebook/digitalent/model/resnet_50.h5')\n",
        "    # Load classes\n",
        "    classes = {}\n",
        "    with open('/content/drive/MyDrive/colab_notebook/digitalent/model/classes.pkl', 'rb') as file:\n",
        "        classes = pickle.load(file)\n",
        "    # Get a list of categories\n",
        "    categories = os.listdir('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/')\n",
        "    # Get a category a random\n",
        "    category = random.choice(categories)\n",
        "    # Print the category\n",
        "    print(category)\n",
        "    # Get images in a categorydd\n",
        "    images =  os.listdir('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/' + category)\n",
        "    # Randomize images to get different images each time\n",
        "    random.shuffle(images)\n",
        "    # Loop images\n",
        "    blocks = []\n",
        "    for i, name in enumerate(images):\n",
        "        # Limit the evaluation\n",
        "        if i > 6:\n",
        "            break;\n",
        "        # Print the name\n",
        "        print(name)\n",
        "        # Get the image\n",
        "        image = cv2.imread('/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/' + category + '/' + name)\n",
        "        # Get input reshaped and rescaled\n",
        "        input = np.array(image).reshape((1, 1078, 1077, 3)).astype('float32')/255\n",
        "        # Get predictions\n",
        "        predictions = model.predict(input).ravel()\n",
        "        # Print predictions\n",
        "        print(predictions)\n",
        "        # Get the class with the highest probability\n",
        "        prediction = np.argmax(predictions)\n",
        "        # Check if the prediction is correct\n",
        "        correct = True if classes[prediction].lower() == category else False\n",
        "        # Draw the image and show the best prediction\n",
        "        image = cv2.resize(image,(256,256))\n",
        "        cv2.putText(image, '{0}: {1} %'.format(classes[prediction], str(round(predictions[prediction] * 100, 2))), (12, 22), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 0), 2)\n",
        "        cv2.putText(image, '{0}: {1} %'.format(classes[prediction], str(round(predictions[prediction] * 100, 2))), (10, 20), cv2.FONT_HERSHEY_DUPLEX, 0.7, (65,105,225), 2)\n",
        "        cv2.putText(image, '{0}'.format('CORRECT!' if correct else 'WRONG!'), (12, 50), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 0), 2)\n",
        "        cv2.putText(image, '{0}'.format('CORRECT!' if correct else 'WRONG!'), (10, 48), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 0) if correct else (0, 0, 255), 2)\n",
        "        \n",
        "        # Append the image\n",
        "        blocks.append(image)\n",
        "        \n",
        "    # Display images and predictions\n",
        "    row1 = np.concatenate(blocks[0:3], axis=1)\n",
        "    row2 = np.concatenate(blocks[3:6], axis=1)\n",
        "    #cv2.imshow('Predictions', np.concatenate((row1, row2), axis=0))\n",
        "    cv2.imwrite('/content/drive/MyDrive/colab_notebook/digitalent/predictions.jpg', np.concatenate((row1, row2), axis=0)) \n",
        "    cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "hse-UIpn-ZND"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "XSsN9HbkyEGC",
        "outputId": "1b198ac0-f935-4242-885f-249dd8f81f92"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "wall white (3).jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3f393ad04e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-7a6b47c09dcb>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/colab_notebook/digitalent/dataset/Citra/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Get input reshaped and rescaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1078\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1077\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 27000000 into shape (1,1078,1077,3)"
          ]
        }
      ]
    }
  ]
}